{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Carregamento e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ks-projects-201801.csv')\n",
    "\n",
    "def to_time(str, mask):\n",
    "    return dt.strptime(str, mask)\n",
    "\n",
    "def col_dict(dataframe, col):\n",
    "    unique_values = dataframe[col].unique()\n",
    "    dc = {}\n",
    "\n",
    "    for idx,val in enumerate(unique_values):\n",
    "        dc[val] = idx\n",
    "\n",
    "    return dc\n",
    "\n",
    "def to_numeric(dataframe, col):\n",
    "    \"\"\" Transforms the values of column col to a numeric mapping.\n",
    "        Returns the transformed dataframe and the dictionary with the mapping.\"\"\"\n",
    "    df = dataframe\n",
    "    dc = col_dict(df, col)\n",
    "    df[col] = df[col].apply(lambda x: dc[x])\n",
    "\n",
    "    return df, dc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "State feature transformation:\n",
    "\n",
    "1 - Removing projects with state equals to 'undefined' or 'live'\n",
    "2 - Change the values to make a binary classification:\n",
    "\n",
    "successful: 1\n",
    "failed: 0\n",
    "canceled: 0\n",
    "suspended': 0\n",
    "\"\"\"\n",
    "\n",
    "df.drop(df[(df.state == 'live') | (df.state == 'undefined')].index, inplace=True)\n",
    "df['state'] = (df['state'] == 'successful').astype(int)\n",
    "\n",
    "\n",
    "\"\"\"Cleans and add columns from columns already in the data\"\"\"\n",
    "# Convert string to datetime and get the \n",
    "# difference in days from beginning to end of the campaign\n",
    "\n",
    "df['running_days'] = (\n",
    "    df['deadline'].apply(to_time, args=('%Y-%m-%d',)) \n",
    "    - df['launched'].apply(to_time, args=('%Y-%m-%d %H:%M:%S',))\n",
    ").apply(lambda x: x.days)\n",
    "  \n",
    "df, cat_dict = to_numeric(df, 'category')\n",
    "df, main_cat_dict = to_numeric(df, 'main_category')\n",
    "df, country_dict = to_numeric(df, 'country')\n",
    "\n",
    "# Removing unused features\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "df.drop('name', axis=1, inplace=True)\n",
    "df.drop('deadline', axis=1, inplace=True)\n",
    "df.drop('launched', axis=1, inplace=True)\n",
    "df.drop('pledged', axis=1, inplace=True)\n",
    "df.drop('usd_pledged', axis=1, inplace=True)\n",
    "df.drop('goal', axis=1, inplace=True)\n",
    "df.drop('currency', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'state'\n",
    "cols_labels = df.columns.values\n",
    "sidx = np.argsort(cols_labels)\n",
    "y_index_column = sidx[np.searchsorted(cols_labels,y_column,sorter=sidx)]\n",
    "\n",
    "values = df.values\n",
    "values_shape = values.shape\n",
    "\n",
    "y = values[:,y_index_column]\n",
    "X = np.concatenate((values[:, 0:y_index_column], values[:,y_index_column+1:values_shape[1]]), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, shuffle=True)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados (média e feature scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_column = 'state'\n",
    "# columns_to_normalize = ['running_days', 'backers', 'usd_pledged_real', 'usd_goal_real']\n",
    "# cols_labels = df.columns.values\n",
    "# sidx = np.argsort(cols_labels)\n",
    "# index_columns = sidx[np.searchsorted(cols_labels,columns_to_normalize,sorter=sidx)]\n",
    "# y_index_columns = sidx[np.searchsorted(cols_labels,y_column,sorter=sidx)]\n",
    "\n",
    "# values = df.values\n",
    "# values_shape = values.shape\n",
    "    \n",
    "# for j in index_columns:\n",
    "#     max_value = np.max(values[:,j])\n",
    "#     min_value = np.min(values[:,j])\n",
    "#     mean = np.sum(values[:,j]) / values_shape[0]\n",
    "\n",
    "#     i = 0\n",
    "#     while i < values_shape[0]:\n",
    "#         values[i, j] = (values[i, j] - mean) / (max_value - min_value)\n",
    "#         i = i + 1\n",
    "\n",
    "# y = values[:,y_index_columns]\n",
    "# X = np.concatenate((values[:, 0:y_index_columns], values[:,y_index_columns+1:values_shape[1]]), axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando convergência do Perceptron para verificar se os dados são linearmente separáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(random_state = 0)\n",
    "perceptron.fit(X_train, y_train)\n",
    "predicted = perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predicted)\n",
    "\n",
    "#plt.clf() \n",
    "#plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "# classNames = ['Negative','Positive']\n",
    "# plt.title('Perceptron Confusion Matrix - Entire Data')\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# tick_marks = np.arange(len(classNames))\n",
    "# plt.xticks(tick_marks, classNames, rotation=45)\n",
    "# plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "  \n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "        #plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "\n",
    "# TODO - Apresentar o gráfico da matriz de confusão\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando convergência do Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\"\"\"\n",
    "\n",
    "#neural_arch = [(1), (2), (3), (4), (5), (6), (7), (8), (9), (10), (11), (12), (13)]\n",
    "#neural_arch = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13)]\n",
    "#classifiers = []\n",
    "#reports = []\n",
    "\n",
    "#for na in neural_arch:\n",
    "#    classifiers.append(MLPClassifier(hidden_layer_sizes=na, max_iter=500, alpha=0.001, solver='adam', verbose=True, tol=0.000000001))\n",
    "\n",
    "#for c in classifiers:\n",
    "#    c.fit(X_train, y_train)\n",
    "#    y_pred = c.predict(X_test)\n",
    "#    reports.append(classification_report(y_test, y_pred))\n",
    "\n",
    "#for r in reports:\n",
    "#    print(r)\n",
    "\n",
    "# c = MLPClassifier(hidden_layer_sizes=(5, 5))\n",
    "\n",
    "c = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=100, alpha=0.01, solver='adam', verbose=True, tol=0.0001)\n",
    "c.fit(X_train, y_train)\n",
    "y_pred = c.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apresentação de métricas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
