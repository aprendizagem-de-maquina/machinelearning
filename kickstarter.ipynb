{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Carregamento e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ks-projects-201801.csv')\n",
    "\n",
    "def to_time(str, mask):\n",
    "    return dt.strptime(str, mask)\n",
    "\n",
    "def col_dict(dataframe, col):\n",
    "    unique_values = dataframe[col].unique()\n",
    "    dc = {}\n",
    "\n",
    "    for idx,val in enumerate(unique_values):\n",
    "        dc[val] = idx\n",
    "\n",
    "    return dc\n",
    "\n",
    "def to_numeric(dataframe, col):\n",
    "    \"\"\" Transforms the values of column col to a numeric mapping.\n",
    "        Returns the transformed dataframe and the dictionary with the mapping.\"\"\"\n",
    "    df = dataframe\n",
    "    dc = col_dict(df, col)\n",
    "    df[col] = df[col].apply(lambda x: dc[x])\n",
    "\n",
    "    return df, dc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "State feature transformation:\n",
    "\n",
    "1 - Removing projects with state equals to 'undefined' or 'live'\n",
    "2 - Change the values to make a binary classification:\n",
    "\n",
    "successful: 1\n",
    "failed: 0\n",
    "canceled: 0\n",
    "suspended': 0\n",
    "\"\"\"\n",
    "\n",
    "df.drop(df[(df.state == 'live') | (df.state == 'undefined')].index, inplace=True)\n",
    "df['state'] = (df['state'] == 'successful').astype(int)\n",
    "\n",
    "\n",
    "\"\"\"Cleans and add columns from columns already in the data\"\"\"\n",
    "# Convert string to datetime and get the \n",
    "# difference in days from beginning to end of the campaign\n",
    "\n",
    "df['running_days'] = (\n",
    "    df['deadline'].apply(to_time, args=('%Y-%m-%d',)) \n",
    "    - df['launched'].apply(to_time, args=('%Y-%m-%d %H:%M:%S',))\n",
    ").apply(lambda x: x.days)\n",
    "  \n",
    "df, cat_dict = to_numeric(df, 'category')\n",
    "df, main_cat_dict = to_numeric(df, 'main_category')\n",
    "df, country_dict = to_numeric(df, 'country')\n",
    "\n",
    "# Removing unused features\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "df.drop('name', axis=1, inplace=True)\n",
    "df.drop('deadline', axis=1, inplace=True)\n",
    "df.drop('launched', axis=1, inplace=True)\n",
    "df.drop('pledged', axis=1, inplace=True)\n",
    "df.drop('usd_pledged', axis=1, inplace=True)\n",
    "df.drop('goal', axis=1, inplace=True)\n",
    "df.drop('currency', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'state'\n",
    "#columns_to_normalize = ['running_days', 'backers', 'usd_pledged_real', 'usd_goal_real']\n",
    "cols_labels = df.columns.values\n",
    "sidx = np.argsort(cols_labels)\n",
    "#index_columns = sidx[np.searchsorted(cols_labels,columns_to_normalize,sorter=sidx)]\n",
    "y_index_column = sidx[np.searchsorted(cols_labels,y_column,sorter=sidx)]\n",
    "\n",
    "values = df.values\n",
    "values_shape = values.shape\n",
    "\n",
    "# Shuffling lines of the matrix\n",
    "np.random.shuffle(values)\n",
    "\n",
    "y = values[:,y_index_column]\n",
    "X = np.concatenate((values[:, 0:y_index_column], values[:,y_index_column+1:values_shape[1]]), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados (média e feature scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_column = 'state'\n",
    "# columns_to_normalize = ['running_days', 'backers', 'usd_pledged_real', 'usd_goal_real']\n",
    "# cols_labels = df.columns.values\n",
    "# sidx = np.argsort(cols_labels)\n",
    "# index_columns = sidx[np.searchsorted(cols_labels,columns_to_normalize,sorter=sidx)]\n",
    "# y_index_columns = sidx[np.searchsorted(cols_labels,y_column,sorter=sidx)]\n",
    "\n",
    "# values = df.values\n",
    "# values_shape = values.shape\n",
    "    \n",
    "# for j in index_columns:\n",
    "#     max_value = np.max(values[:,j])\n",
    "#     min_value = np.min(values[:,j])\n",
    "#     mean = np.sum(values[:,j]) / values_shape[0]\n",
    "\n",
    "#     i = 0\n",
    "#     while i < values_shape[0]:\n",
    "#         values[i, j] = (values[i, j] - mean) / (max_value - min_value)\n",
    "#         i = i + 1\n",
    "\n",
    "# y = values[:,y_index_columns]\n",
    "# X = np.concatenate((values[:, 0:y_index_columns], values[:,y_index_columns+1:values_shape[1]]), axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando convergência do Perceptron para verificar se os dados são linearmente separáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erickbs7/workspaces/machinelearning/env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(random_state = 0)\n",
    "perceptron.fit(X_train, y_train)\n",
    "predicted = perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN = 59572\n",
      "FP = 12151\n",
      "FN = 3844\n",
      "TP = 36123\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predicted)\n",
    "\n",
    "#plt.clf() \n",
    "#plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "# classNames = ['Negative','Positive']\n",
    "# plt.title('Perceptron Confusion Matrix - Entire Data')\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# tick_marks = np.arange(len(classNames))\n",
    "# plt.xticks(tick_marks, classNames, rotation=45)\n",
    "# plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "  \n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "        #plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "\n",
    "# TODO - Apresentar o gráfico da matriz de confusão\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando convergência do Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.56751608\n",
      "Iteration 2, loss = 0.45312673\n",
      "Iteration 3, loss = 0.39018256\n",
      "Iteration 4, loss = 0.34697037\n",
      "Iteration 5, loss = 0.31597909\n",
      "Iteration 6, loss = 0.29357773\n",
      "Iteration 7, loss = 0.27580128\n",
      "Iteration 8, loss = 0.26080811\n",
      "Iteration 9, loss = 0.24799077\n",
      "Iteration 10, loss = 0.23660780\n",
      "Iteration 11, loss = 0.22681914\n",
      "Iteration 12, loss = 0.21837754\n",
      "Iteration 13, loss = 0.21132665\n",
      "Iteration 14, loss = 0.20598759\n",
      "Iteration 15, loss = 0.20101961\n",
      "Iteration 16, loss = 0.19700167\n",
      "Iteration 17, loss = 0.19341813\n",
      "Iteration 18, loss = 0.19030707\n",
      "Iteration 19, loss = 0.18725939\n",
      "Iteration 20, loss = 0.18480332\n",
      "Iteration 21, loss = 0.18252841\n",
      "Iteration 22, loss = 0.18071794\n",
      "Iteration 23, loss = 0.17878009\n",
      "Iteration 24, loss = 0.17684129\n",
      "Iteration 25, loss = 0.17563091\n",
      "Iteration 26, loss = 0.17413025\n",
      "Iteration 27, loss = 0.17290823\n",
      "Iteration 28, loss = 0.17174862\n",
      "Iteration 29, loss = 0.17052906\n",
      "Iteration 30, loss = 0.16962218\n",
      "Iteration 31, loss = 0.16872883\n",
      "Iteration 32, loss = 0.16772595\n",
      "Iteration 33, loss = 0.16713934\n",
      "Iteration 34, loss = 0.16600795\n",
      "Iteration 35, loss = 0.16562897\n",
      "Iteration 36, loss = 0.16500893\n",
      "Iteration 37, loss = 0.16406527\n",
      "Iteration 38, loss = 0.16383281\n",
      "Iteration 39, loss = 0.16306651\n",
      "Iteration 40, loss = 0.16273332\n",
      "Iteration 41, loss = 0.16226266\n",
      "Iteration 42, loss = 0.16154667\n",
      "Iteration 43, loss = 0.16138562\n",
      "Iteration 44, loss = 0.16062049\n",
      "Iteration 45, loss = 0.16012751\n",
      "Iteration 46, loss = 0.16015038\n",
      "Iteration 47, loss = 0.15951315\n",
      "Iteration 48, loss = 0.15889188\n",
      "Iteration 49, loss = 0.15865115\n",
      "Iteration 50, loss = 0.15826473\n",
      "Iteration 51, loss = 0.15799159\n",
      "Iteration 52, loss = 0.15777651\n",
      "Iteration 53, loss = 0.15740448\n",
      "Iteration 54, loss = 0.15707288\n",
      "Iteration 55, loss = 0.15693276\n",
      "Iteration 56, loss = 0.15662049\n",
      "Iteration 57, loss = 0.15629975\n",
      "Iteration 58, loss = 0.15632824\n",
      "Iteration 59, loss = 0.15601184\n",
      "Iteration 60, loss = 0.15563653\n",
      "Iteration 61, loss = 0.15550890\n",
      "Iteration 62, loss = 0.15536031\n",
      "Iteration 63, loss = 0.15518855\n",
      "Iteration 64, loss = 0.15495148\n",
      "Iteration 65, loss = 0.15480469\n",
      "Iteration 66, loss = 0.15452511\n",
      "Iteration 67, loss = 0.15439529\n",
      "Iteration 68, loss = 0.15419789\n",
      "Iteration 69, loss = 0.15406958\n",
      "Iteration 70, loss = 0.15399872\n",
      "Iteration 71, loss = 0.15382535\n",
      "Iteration 72, loss = 0.15371381\n",
      "Iteration 73, loss = 0.15355308\n",
      "Iteration 74, loss = 0.15337630\n",
      "Iteration 75, loss = 0.15335848\n",
      "Iteration 76, loss = 0.15314628\n",
      "Iteration 77, loss = 0.15303509\n",
      "Iteration 78, loss = 0.15300578\n",
      "Iteration 79, loss = 0.15281028\n",
      "Iteration 80, loss = 0.15287337\n",
      "Iteration 81, loss = 0.15260262\n",
      "Iteration 82, loss = 0.15247316\n",
      "Iteration 83, loss = 0.15239472\n",
      "Iteration 84, loss = 0.15226572\n",
      "Iteration 85, loss = 0.15237273\n",
      "Iteration 86, loss = 0.15223458\n",
      "Iteration 87, loss = 0.15212315\n",
      "Iteration 88, loss = 0.15197146\n",
      "Iteration 89, loss = 0.15211958\n",
      "Iteration 90, loss = 0.15186400\n",
      "Iteration 91, loss = 0.15191272\n",
      "Iteration 92, loss = 0.15176031\n",
      "Iteration 93, loss = 0.15174979\n",
      "Iteration 94, loss = 0.15165967\n",
      "Iteration 95, loss = 0.15156082\n",
      "Iteration 96, loss = 0.15154908\n",
      "Iteration 97, loss = 0.15153556\n",
      "Iteration 98, loss = 0.15157993\n",
      "Iteration 99, loss = 0.15134346\n",
      "Iteration 100, loss = 0.15129544\n",
      "111690\n",
      "107682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erickbs7/workspaces/machinelearning/env/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# test_X = X[0:500,:]\n",
    "# test_y = y[0:500]\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(7,), max_iter=100, alpha=0.01, solver='adam', verbose=True, tol=0.000000001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "c = 0\n",
    "i = 0\n",
    "while i < y_test.shape[0]:\n",
    "    if y_test[i] == y_pred[i]:\n",
    "        c = c + 1\n",
    "    i = i + 1\n",
    "print(y_test.shape[0])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
